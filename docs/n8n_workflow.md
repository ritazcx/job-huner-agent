# n8n Workflow Design â€“ Job Hunter Agent

This document describes the node-level design of the **Job Hunter Agent**, implemented as an n8n workflow running in Docker.

---

## ğŸ§  Workflow Overview

```text
Cron Trigger
   â†“
Read Resume (Local PDF)
   â†“
Extract Resume Text
   â†“
Resume â†’ Structured JSON (LLM)
   â†“
Job Source (Google Jobs / API)
   â†“
Split Jobs
   â†“
JD Parser (LLM)
   â†“
CV â†” JD Matcher (LLM)
   â†“
Scoring Function
   â†“
Sort & Top N
   â†“
Daily Email Digest
```

---

## ğŸ“¦ Node Details

### 1. Cron Trigger

* Runs daily at 07:00
* Initiates the agent workflow

### 2. Read Binary File

* Reads resume from `/data/resume/CV_latest.pdf`
* Mounted via Docker volume

### 3. PDF Extract

* Extracts raw text from resume PDF

### 4. Resume Parser (LLM)

* Converts resume text into structured JSON
* Cached for reuse

### 5. Job Source

* Fetches job postings from the last 24 hours
* Uses API-based sources (no scraping)

### 6. Split In Batches

* Processes jobs one by one

### 7. JD Parser (LLM)

* Extracts structured requirements from job descriptions

### 8. CV â†” JD Matcher

* Computes semantic similarity
* Produces explainable matching results

### 9. Scoring Function

* Weighted scoring based on:

  * Skill match
  * Experience match
  * Language constraints

### 10. Notification

* Sends daily digest via Email / Notion / Slack

---

## ğŸ³ Docker Notes

Ensure the following volume mapping exists:

```yaml
volumes:
  - ./data:/data
```

This allows n8n to access local resume and cache files.

---

## ğŸ¯ Goal

This workflow is designed to:

* Minimize human job search effort
* Maximize application relevance
* Provide transparent, explainable job recommendations
